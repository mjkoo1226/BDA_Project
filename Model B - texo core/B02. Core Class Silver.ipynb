{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ebf03ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from utils import *\n",
    "import copy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, ConcatDataset\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9dfe7980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default paths\n",
    "ROOT = Path(\"Amazon_products\")\n",
    "TRAIN_PATH = ROOT / \"train\"\n",
    "TEST_PATH = ROOT / \"test\"\n",
    "\n",
    "TRAIN_CORPUS_PATH = TRAIN_PATH / \"train_corpus.txt\"\n",
    "TEST_CORPUS_PATH = TEST_PATH  / \"test_corpus.txt\"\n",
    "CLASSES_PATH = ROOT / \"classes.txt\"\n",
    "HIERARCHY_PATH = ROOT / \"class_hierarchy.txt\"\n",
    "REL_KEYWORDS_PATH = ROOT / \"class_related_keywords.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e7b3b2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#train=29,487  #test=19,658\n"
     ]
    }
   ],
   "source": [
    "# ---------- Read-only loads ----------\n",
    "\n",
    "train_pid2text    = load_pid2text(TRAIN_CORPUS_PATH)\n",
    "test_pid2text     = load_pid2text(TEST_CORPUS_PATH)\n",
    "classes_int       = load_classes_int(CLASSES_PATH)\n",
    "classes_str       = load_classes_str(CLASSES_PATH)\n",
    "rel_keywords      = load_keywords(REL_KEYWORDS_PATH)\n",
    "class_graph_edges = load_class_graph(HIERARCHY_PATH)\n",
    "\n",
    "print(f\"#train={len(train_pid2text):,}  #test={len(test_pid2text):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6966ea7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roots: [0, 3, 23]\n"
     ]
    }
   ],
   "source": [
    "from collections import deque\n",
    "\n",
    "num_classes = len(classes_int)\n",
    "\n",
    "# 1) 무방향 인접 리스트 만들기\n",
    "adj = [[] for _ in range(num_classes)]\n",
    "for a, b in class_graph_edges:\n",
    "    adj[a].append(b)\n",
    "    adj[b].append(a)\n",
    "\n",
    "# 2) parent/children 초기화\n",
    "parents = [[] for _ in range(num_classes)]   # 각 노드의 부모 리스트 (0 또는 1개 들어감)\n",
    "children = [[] for _ in range(num_classes)]  # 각 노드의 자식들\n",
    "visited = [False] * num_classes\n",
    "root_classes = []\n",
    "\n",
    "# 3) 각 연결요소마다 하나씩 root 잡고 BFS\n",
    "for start in range(num_classes):\n",
    "    if visited[start]:\n",
    "        continue\n",
    "\n",
    "    # start를 이 연결요소의 root로 선택\n",
    "    root = start\n",
    "    root_classes.append(root)\n",
    "\n",
    "    visited[root] = True\n",
    "    q = deque([root])\n",
    "\n",
    "    while q:\n",
    "        u = q.popleft()\n",
    "        for v in adj[u]:\n",
    "            if not visited[v]:\n",
    "                visited[v] = True\n",
    "                # u -> v 방향으로 트리 엣지 잡기\n",
    "                parents[v].append(u)\n",
    "                children[u].append(v)\n",
    "                q.append(v)\n",
    "\n",
    "# 이제:\n",
    "# parents[c]  = [parent] 또는 [] (root인 경우)\n",
    "# children[c] = [자식 리스트]\n",
    "# root_classes = 각 연결요소의 root들\n",
    "print(\"roots:\", root_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00443160",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMB_PATH = Path(\"Embeddings\")\n",
    "\n",
    "train_emb_dict = load_json(EMB_PATH / \"train_embeddings.json\")\n",
    "test_emb_dict  = load_json(EMB_PATH / \"test_embeddings.json\")\n",
    "class_emb_dict = load_json(EMB_PATH / \"class_embeddings.json\")\n",
    "\n",
    "train_emb = torch.tensor(list(train_emb_dict.values())) # (N, d)\n",
    "test_emb  = torch.tensor(list(test_emb_dict.values()))  # (N', d)\n",
    "class_emb = torch.tensor(list(class_emb_dict.values())) # (C, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f315b85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_embs   = F.normalize(train_emb, p=2, dim=1)   # (N, d)\n",
    "class_embs = F.normalize(class_emb, p=2, dim=1)   # (C, d)\n",
    "\n",
    "def compute_doc_class_sim(doc_embs, class_embs, batch_size=512):\n",
    "    \"\"\"\n",
    "    doc_embs: (N_docs, d)\n",
    "    class_embs: (N_classes, d)\n",
    "    return: sim_matrix (N_docs, N_classes)  ㅡ 코사인 유사도\n",
    "    \"\"\"\n",
    "    sims = []\n",
    "    n_docs = doc_embs.size(0)\n",
    "    for start in range(0, n_docs, batch_size):\n",
    "        end = min(start + batch_size, n_docs)\n",
    "        batch = doc_embs[start:end]           # (B, d)\n",
    "        # 코사인 유사도 == 정규화 후 matmul\n",
    "        sim_batch = batch @ class_embs.T      # (B, N_classes)\n",
    "        sims.append(sim_batch)\n",
    "    sims = torch.cat(sims, dim=0)             # (N_docs, N_classes)\n",
    "    return sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "39c5b783",
   "metadata": {},
   "outputs": [],
   "source": [
    "from heapq import nlargest\n",
    "\n",
    "def mine_candidates_for_doc(sim_row,\n",
    "                            root_classes,\n",
    "                            children,\n",
    "                            beam_width=10,\n",
    "                            min_sim=-0.1,\n",
    "                            max_depth=10):\n",
    "    \"\"\"\n",
    "    sim_row: (N_classes,)  - 이 문서와 각 class의 similarity\n",
    "    return: candidate_classes: set[int]\n",
    "    \"\"\"\n",
    "\n",
    "    # 초기 beam: root 노드들\n",
    "    # element: (path_nodes, path_score)\n",
    "    beam = []\n",
    "    for r in root_classes:\n",
    "        s = sim_row[r].item()\n",
    "        if s >= min_sim:\n",
    "            beam.append(([r], s))\n",
    "    candidate_classes = set([r for r, in [(r,) for r in root_classes]])\n",
    "\n",
    "    depth = 0\n",
    "    while beam and depth < max_depth:\n",
    "        new_beam = []\n",
    "        for path, path_score in beam:\n",
    "            last = path[-1]\n",
    "            for child in children[last]:\n",
    "                s = sim_row[child].item()\n",
    "                if s < min_sim:\n",
    "                    continue\n",
    "                # 경로 점수: 평균으로 예시\n",
    "                new_score = (path_score * len(path) + s) / (len(path) + 1)\n",
    "                new_path = path + [child]\n",
    "                new_beam.append((new_path, new_score))\n",
    "                candidate_classes.add(child)\n",
    "\n",
    "        # 상위 beam_width 개만 유지\n",
    "        if not new_beam:\n",
    "            break\n",
    "        beam = nlargest(beam_width, new_beam, key=lambda x: x[1])\n",
    "        depth += 1\n",
    "\n",
    "    return candidate_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "441bb0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_local_confidence_for_doc(sim_row, c, parents, children):\n",
    "    \"\"\"\n",
    "    sim_row: (N_classes,) for document D\n",
    "    c: class index\n",
    "    parents: list of list\n",
    "    children: list of list\n",
    "    \"\"\"\n",
    "    parent_ids = parents[c]\n",
    "    sibling_ids = set()\n",
    "    for p in parent_ids:\n",
    "        for ch in children[p]:\n",
    "            if ch != c:\n",
    "                sibling_ids.add(ch)\n",
    "    compare_ids = list(parent_ids) + list(sibling_ids)\n",
    "\n",
    "    if not compare_ids:  # 루트급이면 margin 정의가 애매하니 0으로 둘 수도, 그냥 sim만 쓸 수도\n",
    "        return 0.0\n",
    "\n",
    "    max_ps = sim_row[compare_ids].max().item()\n",
    "    conf = sim_row[c].item() - max_ps\n",
    "    return conf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "488e8e15",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 22\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# 2) 후보에 대해서만 local margin 계산\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m cand_classes:\n\u001b[1;32m---> 22\u001b[0m     conf \u001b[38;5;241m=\u001b[39m compute_local_confidence_for_doc(\n\u001b[0;32m     23\u001b[0m         sim_row, c, parents\u001b[38;5;241m=\u001b[39mparents, children\u001b[38;5;241m=\u001b[39mchildren\n\u001b[0;32m     24\u001b[0m     )\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;66;03m# conf가 너무 작거나 음수인 건 버릴 수도 있음\u001b[39;00m\n\u001b[0;32m     26\u001b[0m     all_conf_values[c]\u001b[38;5;241m.\u001b[39mappend(conf)\n",
      "Cell \u001b[1;32mIn[12], line 19\u001b[0m, in \u001b[0;36mcompute_local_confidence_for_doc\u001b[1;34m(sim_row, c, parents, children)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m compare_ids:  \u001b[38;5;66;03m# 루트급이면 margin 정의가 애매하니 0으로 둘 수도, 그냥 sim만 쓸 수도\u001b[39;00m\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m---> 19\u001b[0m max_ps \u001b[38;5;241m=\u001b[39m sim_row[compare_ids]\u001b[38;5;241m.\u001b[39mmax()\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     20\u001b[0m conf \u001b[38;5;241m=\u001b[39m sim_row[c]\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m-\u001b[39m max_ps\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m conf\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_docs, num_classes = doc_embs.size(0), class_embs.size(0)\n",
    "sim_matrix = compute_doc_class_sim(doc_embs, class_embs)  # (N_docs, N_classes)\n",
    "\n",
    "all_conf_values = [[] for _ in range(num_classes)]  # per-class conf list\n",
    "candidate_per_doc = []\n",
    "\n",
    "for i in range(num_docs):\n",
    "    sim_row = sim_matrix[i]  # (N_classes,)\n",
    "    # 1) top-down candidate mining\n",
    "    cand_classes = mine_candidates_for_doc(\n",
    "        sim_row,\n",
    "        root_classes=root_classes,\n",
    "        children=children,\n",
    "        beam_width=10,\n",
    "        min_sim=-0.1,\n",
    "        max_depth=10\n",
    "    )\n",
    "    candidate_per_doc.append(cand_classes)\n",
    "    \n",
    "    # 2) 후보에 대해서만 local margin 계산\n",
    "    for c in cand_classes:\n",
    "        conf = compute_local_confidence_for_doc(\n",
    "            sim_row, c, parents=parents, children=children\n",
    "        )\n",
    "        # conf가 너무 작거나 음수인 건 버릴 수도 있음\n",
    "        all_conf_values[c].append(conf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796f2173",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class_median_conf = np.zeros(num_classes)\n",
    "for c in range(num_classes):\n",
    "    vals = all_conf_values[c]\n",
    "    if len(vals) == 0:\n",
    "        class_median_conf[c] = float('inf')  # core 안 생기게\n",
    "    else:\n",
    "        class_median_conf[c] = np.median(vals)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df500b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "core_classes_per_doc = [[] for _ in range(num_docs)]\n",
    "\n",
    "for i in range(num_docs):\n",
    "    sim_row = sim_matrix[i]\n",
    "    cand_classes = candidate_per_doc[i]\n",
    "    for c in cand_classes:\n",
    "        conf = compute_local_confidence_for_doc(\n",
    "            sim_row, c, parents=parents, children=children\n",
    "        )\n",
    "        if conf >= class_median_conf[c]:\n",
    "            core_classes_per_doc[i].append(c)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
