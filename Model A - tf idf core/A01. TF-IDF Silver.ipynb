{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "faa017de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import torch\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e096765c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default paths\n",
    "ROOT = Path(\"Amazon_products\")\n",
    "TRAIN_PATH = ROOT / \"train\"\n",
    "TEST_PATH = ROOT / \"test\"\n",
    "\n",
    "TRAIN_CORPUS_PATH = TRAIN_PATH / \"train_corpus.txt\"\n",
    "TEST_CORPUS_PATH = TEST_PATH  / \"test_corpus.txt\"\n",
    "CLASSES_PATH = ROOT / \"classes.txt\"\n",
    "HIERARCHY_PATH = ROOT / \"class_hierarchy.txt\"\n",
    "REL_KEYWORDS_PATH = ROOT / \"class_related_keywords.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a431c11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Function for loads ----------\n",
    "\n",
    "def load_lines(p: Path):\n",
    "    with p.open(\"r\", encoding=\"utf-8\") as f:\n",
    "        return [line.rstrip(\"\\n\") for line in f]\n",
    "\n",
    "def load_pid2text(p: Path):\n",
    "    \"\"\"TSV: pid \\\\t text  -> dict[pid]=text\"\"\"\n",
    "    pid2text = {}\n",
    "    with p.open(\"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            parts = line.rstrip(\"\\n\").split(\"\\t\", 1)\n",
    "            if len(parts) == 2:\n",
    "                pid, text = parts\n",
    "                pid2text[pid] = text\n",
    "    return pid2text\n",
    "\n",
    "def load_classes_int(p: Path):\n",
    "    class_dict = {}\n",
    "    with p.open(\"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            label_int, label_str = line.rstrip(\"\\n\").split(\"\\t\")\n",
    "            class_dict[int(label_int)] = label_str\n",
    "    return class_dict\n",
    "\n",
    "def load_classes_str(p: Path):\n",
    "    class_dict = {}\n",
    "    with p.open(\"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            label_int, label_str = line.rstrip(\"\\n\").split(\"\\t\")\n",
    "            class_dict[label_str] = int(label_int)\n",
    "    return class_dict\n",
    "\n",
    "def load_keywords(p: Path):\n",
    "    keywords = {}\n",
    "    with p.open(\"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            key, items = line.rstrip(\"\\n\").split(\":\")\n",
    "            item_list = [item for item in items.split(\",\")]\n",
    "            keywords[key] = item_list\n",
    "    return keywords\n",
    "\n",
    "def load_class_graph(p: Path):\n",
    "    edges = []\n",
    "    with p.open(\"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            p, c = map(int, line.rstrip(\"\\n\").split(\"\\t\"))\n",
    "            edges.append((p, c))\n",
    "    return edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c6bc1b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#train=29,487  #test=19,658\n"
     ]
    }
   ],
   "source": [
    "# ---------- Read-only loads ----------\n",
    "\n",
    "train_pid2text    = load_pid2text(TRAIN_CORPUS_PATH)\n",
    "test_pid2text     = load_pid2text(TEST_CORPUS_PATH)\n",
    "classes_int       = load_classes_int(CLASSES_PATH)\n",
    "classes_str       = load_classes_str(CLASSES_PATH)\n",
    "rel_keywords      = load_keywords(REL_KEYWORDS_PATH)\n",
    "class_graph_edges = load_class_graph(HIERARCHY_PATH)\n",
    "\n",
    "print(f\"#train={len(train_pid2text):,}  #test={len(test_pid2text):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49367d75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#nodes=531  #edges=568  #roots=6\n"
     ]
    }
   ],
   "source": [
    "# 부모/자식 dict (정수 라벨 ID 기준)\n",
    "from collections import defaultdict\n",
    "\n",
    "parents = defaultdict(list)\n",
    "children = defaultdict(list)\n",
    "for p_id, c_id in class_graph_edges:\n",
    "    parents[c_id].append(p_id)\n",
    "    children[p_id].append(c_id)\n",
    "\n",
    "roots = [cid for cid in classes_int.keys() if cid not in parents]  # 부모 없는 라벨\n",
    "print(f\"#nodes={len(classes_int)}  #edges={len(class_graph_edges)}  #roots={len(roots)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f370c92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 'grocery_gourmet_food snacks condiments beverages specialty_foods spices cooking_oils baking_ingredients gourmet_chocolates artisanal_cheeses organic_foods'), (1, 'meat_poultry butcher cuts marination grilling roasting seasoning halal organic deli marbling'), (2, 'jerky beef turkey chicken venison buffalo kangaroo elk ostrich bison spicy')]\n"
     ]
    }
   ],
   "source": [
    "# class_related_keywords.txt 는 \"class_str:kw1,kw2,...\" 형식\n",
    "# → 정수 라벨 ID -> 텍스트 로 매핑\n",
    "def build_label_texts(classes_int, rel_keywords):\n",
    "    id2text = {}\n",
    "    for cid, cname in classes_int.items():          # cid=int, cname=str\n",
    "        kws = rel_keywords.get(cname, [])           # 키는 class_str\n",
    "        id2text[cid] = (cname + \" \" + \" \".join(kws)).strip()\n",
    "    return id2text\n",
    "\n",
    "label_texts = build_label_texts(classes_int, rel_keywords)\n",
    "print(list(label_texts.items())[:3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41b98f58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19658, 531)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "\n",
    "# 문서 텍스트(학습은 train으로, 변환은 test로)\n",
    "train_ids, train_texts = zip(*train_pid2text.items())\n",
    "test_ids,  test_texts  = zip(*test_pid2text.items())\n",
    "\n",
    "vec = TfidfVectorizer(max_features=100_000, ngram_range=(1,2), min_df=2)\n",
    "X_train = vec.fit_transform(train_texts)   # 학습\n",
    "X_test  = vec.transform(test_texts)        # 변환\n",
    "\n",
    "# 라벨 텍스트도 같은 vocab으로\n",
    "# 라벨 ID의 고정 순서를 확보 (정렬하면 나중에 index-라벨ID 매핑이 쉬움)\n",
    "label_ids_sorted = sorted(classes_int.keys())   # [0,1,2,...]\n",
    "label_text_list  = [label_texts[cid] for cid in label_ids_sorted]\n",
    "X_labels = vec.transform(label_text_list)\n",
    "\n",
    "# 점수 행렬 (n_test x n_labels)\n",
    "S = X_test @ X_labels.T\n",
    "S = S.tocsr()   # 행별 접근이 쉬움\n",
    "S.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8bcec4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def force_include_parents(pred_set_ids):\n",
    "    \"\"\"부모를 모두 포함시키는 규칙(정수 라벨 ID 사용)\"\"\"\n",
    "    stack = list(pred_set_ids)\n",
    "    while stack:\n",
    "        v = stack.pop()\n",
    "        for p in parents.get(v, []):\n",
    "            if p not in pred_set_ids:\n",
    "                pred_set_ids.add(p)\n",
    "                stack.append(p)\n",
    "    return pred_set_ids\n",
    "\n",
    "def decode_row(scores_csr_row, k=3):\n",
    "    # scores_csr_row: CSR 행 (1 x n_labels)\n",
    "    scores = scores_csr_row.toarray().ravel()\n",
    "    if k <= 0 or scores.size == 0:\n",
    "        return []\n",
    "    \n",
    "    # top-k 인덱스(라벨 index, label_ids_sorted 기준)\n",
    "    idx = np.argpartition(scores, -k)[-k:]\n",
    "    idx = idx[np.argsort(-scores[idx])]\n",
    "    \n",
    "    # index -> 실제 정수 라벨 ID로 변환\n",
    "    pred_ids = { label_ids_sorted[i] for i in idx }\n",
    "    \n",
    "    # 부모 강제 포함\n",
    "    pred_ids = force_include_parents(pred_ids)\n",
    "    \n",
    "    # 너무 늘어나면 점수 상위 k개만 남기기\n",
    "    # (강제 포함된 부모들 중 점수 낮은 것들은 잘리지만, 필요하면 k를 늘려도 됨)\n",
    "    keep = sorted(list(pred_ids), key=lambda cid: scores[label_ids_sorted.index(cid)], reverse=True)[:k]\n",
    "    return keep\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f6b01f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved at outputs/tf-idf-silver.csv\n"
     ]
    }
   ],
   "source": [
    "import os, csv\n",
    "os.makedirs(\"outputs\", exist_ok=True)\n",
    "\n",
    "SUBMISSION_PATH = \"outputs/tf-idf-silver.csv\"\n",
    "\n",
    "# train 전용 점수 행렬 생성\n",
    "S_train = X_train @ X_labels.T\n",
    "S_train = S_train.tocsr()\n",
    "\n",
    "with open(SUBMISSION_PATH, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"id\", \"labels\"])\n",
    "    for row_i, pid in enumerate(train_ids):  # train 파일의 원 순서를 그대로 유지\n",
    "        labels = decode_row(S_train[row_i], k=3)  # [정수 라벨ID,...]\n",
    "        writer.writerow([pid, \",\".join(map(str, labels))])\n",
    "\n",
    "print(\"File saved at\", SUBMISSION_PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
